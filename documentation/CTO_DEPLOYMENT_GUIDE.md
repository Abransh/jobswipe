# ğŸš€ JobSwipe Production Deployment Guide
## CTO-Level Strategic Deployment Plan

**Document Version:** 1.0
**Last Updated:** 2025-11-10
**Prepared By:** DevOps CTO
**Audience:** CEO & Technical Leadership

---

## ğŸ“‹ Executive Summary

This guide provides a **battle-tested, production-ready deployment strategy** for the JobSwipe platform. Based on comprehensive repository analysis, this plan minimizes risk, ensures business continuity, and provides clear rollback procedures.

### What We're Deploying

JobSwipe is a **sophisticated monorepo application** consisting of:

1. **Web Application** (Next.js 15) - User-facing job browsing interface
2. **API Server** (Fastify) - Backend business logic and authentication
3. **Desktop Application** (Electron) - AI-powered browser automation
4. **Job Scraper** (Node.js) - Internal tool for populating job database

### Critical Infrastructure Dependencies

| Service | Purpose | Criticality | Failure Impact |
|---------|---------|-------------|----------------|
| **PostgreSQL 16** | Primary data store | ğŸ”´ CRITICAL | Complete system failure |
| **Redis 7** | Session management, queues | ğŸ”´ CRITICAL | No automation, no sessions |
| **AWS S3** | Resume & file storage | ğŸŸ¡ HIGH | Upload failures |
| **Anthropic API** | AI automation | ğŸŸ¡ HIGH | Automation degraded |
| **OpenAI API** | Fallback AI | ğŸŸ¢ MEDIUM | Graceful degradation |

---

## âš ï¸ CRITICAL PRE-DEPLOYMENT CHECKLIST

### Before You Start - MUST READ

**ğŸš¨ This deployment requires preparation. DO NOT rush this process.**

- [ ] **Budget Confirmed**: Estimated $200-500/month for production infrastructure
- [ ] **Domain Ready**: DNS configured and propagated (24-48 hours lead time)
- [ ] **API Keys Secured**: Anthropic, OpenAI, AWS credentials obtained
- [ ] **Database Backup Plan**: Automated backups configured
- [ ] **Team Availability**: 4-6 hours blocked for deployment window
- [ ] **Testing Environment**: Staging environment available for dry run

### Consequences of Skipping Steps

â›” **Missing Database Backups** â†’ Permanent data loss if migration fails
â›” **Wrong Environment Variables** â†’ Security vulnerabilities, app crashes
â›” **Insufficient Server Resources** â†’ Poor performance, user frustration
â›” **No Rollback Plan** â†’ Extended downtime during issues

---

## ğŸ—ï¸ System Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PRODUCTION SETUP                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚   Web App    â”‚â—„â”€â”€â”€â”€â–ºâ”‚  API Server  â”‚                â”‚
â”‚  â”‚  (Next.js)   â”‚      â”‚  (Fastify)   â”‚                â”‚
â”‚  â”‚ Port: 3000   â”‚      â”‚ Port: 3001   â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚         â–²                     â”‚                         â”‚
â”‚         â”‚                     â–¼                         â”‚
â”‚         â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚         â”‚              â”‚ PostgreSQL   â”‚                 â”‚
â”‚         â”‚              â”‚  (Primary DB)â”‚                 â”‚
â”‚         â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚         â”‚                     â–²                         â”‚
â”‚         â”‚                     â”‚                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚Desktop App  â”‚       â”‚    Redis     â”‚                â”‚
â”‚  â”‚ (Electron)  â”‚â—„â”€â”€â”€â”€â”€â–ºâ”‚ (Queue+Cache)â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚         â”‚                                               â”‚
â”‚         â–¼                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚  Browser    â”‚       â”‚   AWS S3     â”‚                â”‚
â”‚  â”‚ Automation  â”‚       â”‚  (Resumes)   â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Resource Requirements

### Minimum Production Specifications

#### **API Server**
- **CPU**: 2 vCPUs (4 recommended)
- **RAM**: 4GB minimum (8GB recommended)
- **Storage**: 50GB SSD
- **OS**: Ubuntu 22.04 LTS

#### **Database Server (PostgreSQL)**
- **RAM**: 8GB minimum (16GB recommended)
- **Storage**: 100GB SSD with auto-scaling
- **Connections**: 100 max connections
- **Backups**: Daily automated backups with 30-day retention

#### **Redis Cache**
- **RAM**: 2GB minimum (4GB recommended)
- **Persistence**: AOF + RDB snapshots
- **High Availability**: Optional (but recommended)

#### **Web Application**
- **Platform**: Vercel (recommended) or self-hosted
- **Serverless Functions**: Node.js 20 runtime
- **Edge Network**: Global CDN required

---

## ğŸ” Environment Variables - COMPLETE LIST

### Critical Security Variables (MUST CHANGE FROM DEFAULTS)

```bash
# ============================================================================
# AUTHENTICATION & SECURITY (CRITICAL - GENERATE UNIQUE VALUES)
# ============================================================================
JWT_SECRET="<64-char-random-string>"           # Generate: openssl rand -base64 48
JWT_REFRESH_SECRET="<64-char-random-string>"   # Generate: openssl rand -base64 48
SESSION_SECRET="<32-char-random-string>"       # Generate: openssl rand -base64 32
CSRF_SECRET="<32-char-random-string>"          # Generate: openssl rand -base64 32

# ============================================================================
# DATABASE CONNECTION (CRITICAL - PRODUCTION CREDENTIALS)
# ============================================================================
DATABASE_URL="postgresql://user:password@host:5432/jobswipe_prod?sslmode=require"
# Format: postgresql://[USER]:[PASSWORD]@[HOST]:[PORT]/[DATABASE]?sslmode=require
# IMPORTANT: MUST use SSL in production (sslmode=require)

# ============================================================================
# REDIS CONNECTION (CRITICAL - SESSION STORAGE)
# ============================================================================
REDIS_URL="redis://default:password@host:6379"
# Format: redis://[USER]:[PASSWORD]@[HOST]:[PORT]
# Note: Redis stores sessions - if Redis fails, users get logged out

# ============================================================================
# AWS S3 STORAGE (HIGH PRIORITY - FILE UPLOADS)
# ============================================================================
AWS_ACCESS_KEY_ID="AKIA..."
AWS_SECRET_ACCESS_KEY="..."
AWS_REGION="us-east-1"
AWS_S3_BUCKET="jobswipe-production-resumes"

# ============================================================================
# AI SERVICES (HIGH PRIORITY - AUTOMATION FEATURES)
# ============================================================================
ANTHROPIC_API_KEY="sk-ant-..."     # Primary AI for automation
OPENAI_API_KEY="sk-..."            # Fallback AI service
GOOGLE_API_KEY="..."               # Optional: Gemini for diversity

# ============================================================================
# APPLICATION CONFIGURATION
# ============================================================================
NODE_ENV="production"
API_PORT="3001"
API_HOST="0.0.0.0"
NEXT_PUBLIC_API_URL="https://api.yourdomain.com"
NEXT_PUBLIC_APP_URL="https://yourdomain.com"

# ============================================================================
# CORS & SECURITY HEADERS
# ============================================================================
API_CORS_ORIGIN="https://yourdomain.com,https://www.yourdomain.com"
ALLOWED_ORIGINS="https://yourdomain.com,https://www.yourdomain.com"

# ============================================================================
# RATE LIMITING (PREVENTS API ABUSE)
# ============================================================================
RATE_LIMIT_MAX_REQUESTS="100"      # Max requests per window
RATE_LIMIT_WINDOW="900000"         # 15 minutes in milliseconds

# ============================================================================
# MONITORING & LOGGING
# ============================================================================
LOG_LEVEL="info"                   # Use 'info' for production
SENTRY_DSN="..."                   # Optional: Error tracking
MONITORING_ENABLED="true"

# ============================================================================
# EMAIL SERVICE (OPTIONAL - FOR NOTIFICATIONS)
# ============================================================================
SMTP_HOST="smtp.sendgrid.net"
SMTP_PORT="587"
SMTP_USER="apikey"
SMTP_PASSWORD="SG...."
```

### Environment Variable Validation Script

Create this script to validate before deployment:

```bash
#!/bin/bash
# validate-env.sh

echo "ğŸ” Validating Environment Variables..."

required_vars=(
  "JWT_SECRET"
  "DATABASE_URL"
  "REDIS_URL"
  "AWS_ACCESS_KEY_ID"
  "AWS_SECRET_ACCESS_KEY"
  "ANTHROPIC_API_KEY"
)

missing_vars=()

for var in "${required_vars[@]}"; do
  if [ -z "${!var}" ]; then
    missing_vars+=("$var")
  fi
done

if [ ${#missing_vars[@]} -eq 0 ]; then
  echo "âœ… All required environment variables are set"
  exit 0
else
  echo "âŒ Missing required environment variables:"
  printf '  - %s\n' "${missing_vars[@]}"
  exit 1
fi
```

---

## ğŸš€ DEPLOYMENT OPTIONS

### Option 1: Quick Deploy (Recommended for MVP Launch)

**Timeline**: 4-6 hours
**Complexity**: Medium
**Cost**: $200-300/month
**Best For**: Fast market entry, validated MVP

**Stack:**
- Vercel (Web + API)
- Neon/Supabase (Managed PostgreSQL)
- Upstash (Managed Redis)
- AWS S3 (File storage)

### Option 2: Cloud Provider Deploy (Recommended for Scale)

**Timeline**: 1-2 days
**Complexity**: High
**Cost**: $500-1000/month
**Best For**: Expected high traffic, enterprise features

**Stack:**
- AWS/GCP/Azure (Full infrastructure)
- RDS/Cloud SQL (Managed database)
- ElastiCache/Memorystore (Managed Redis)
- S3/Cloud Storage (Files)

### Option 3: Self-Hosted (Maximum Control)

**Timeline**: 2-3 days
**Complexity**: Very High
**Cost**: $100-200/month + DevOps time
**Best For**: Specific compliance requirements, cost optimization

**Stack:**
- DigitalOcean/Hetzner (VPS)
- Self-managed PostgreSQL
- Self-managed Redis
- Self-managed backups

---

## ğŸ“ STEP-BY-STEP: Option 1 - Quick Deploy (RECOMMENDED)

### Phase 1: Infrastructure Setup (60 minutes)

#### Step 1.1: Set Up Managed PostgreSQL (15 min)

**Option A: Neon (Recommended - Serverless)**
```bash
# 1. Go to https://neon.tech
# 2. Create account
# 3. Create new project: "jobswipe-production"
# 4. Copy connection string
# 5. Enable connection pooling
```

**Option B: Supabase**
```bash
# 1. Go to https://supabase.com
# 2. Create new project: "jobswipe-production"
# 3. Copy PostgreSQL connection string (NOT Supabase URL)
# 4. Enable SSL mode
```

**ğŸ¯ Action**: Save `DATABASE_URL` - you'll need this later

#### Step 1.2: Set Up Managed Redis (10 min)

**Upstash Redis (Recommended)**
```bash
# 1. Go to https://upstash.com
# 2. Create account
# 3. Create Redis database: "jobswipe-cache"
# 4. Copy REDIS_URL
# 5. Enable TLS
```

**ğŸ¯ Action**: Save `REDIS_URL` - you'll need this later

#### Step 1.3: Set Up AWS S3 (20 min)

```bash
# 1. Log into AWS Console
# 2. Go to S3
# 3. Create bucket: "jobswipe-production-resumes"
# 4. Enable versioning
# 5. Block public access (we'll use signed URLs)
# 6. Create IAM user: "jobswipe-s3-access"
# 7. Attach policy: AmazonS3FullAccess (or create restrictive policy)
# 8. Generate access key
```

**Recommended S3 Bucket Policy**:
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "AllowJobSwipeUpload",
      "Effect": "Allow",
      "Principal": {
        "AWS": "arn:aws:iam::YOUR_ACCOUNT_ID:user/jobswipe-s3-access"
      },
      "Action": [
        "s3:PutObject",
        "s3:GetObject",
        "s3:DeleteObject"
      ],
      "Resource": "arn:aws:s3:::jobswipe-production-resumes/*"
    }
  ]
}
```

**ğŸ¯ Action**: Save `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_S3_BUCKET`

#### Step 1.4: Get API Keys (15 min)

**Anthropic Claude API**
```bash
# 1. Go to https://console.anthropic.com
# 2. Create API key
# 3. Note: $5 minimum credit required
# 4. Enable billing alerts
```

**OpenAI API (Optional but recommended)**
```bash
# 1. Go to https://platform.openai.com
# 2. Create API key
# 3. Set usage limits ($50/month recommended)
```

**ğŸ¯ Action**: Save `ANTHROPIC_API_KEY`, `OPENAI_API_KEY`

---

### Phase 2: Database Setup (30 minutes)

#### Step 2.1: Run Prisma Migrations

```bash
# From your local machine:

# 1. Install dependencies
cd /home/user/jobswipe
npm install

# 2. Set DATABASE_URL temporarily
export DATABASE_URL="<your-production-database-url>"

# 3. Generate Prisma Client
npm run db:generate

# 4. Deploy migrations to production database
cd packages/database
npx prisma migrate deploy

# Expected output:
# âœ… 5 migrations applied successfully
# âœ… Database schema is up to date
```

#### Step 2.2: Verify Database Schema

```bash
# Connect to database and verify tables exist
npx prisma studio

# You should see these tables:
# - users
# - user_profiles
# - user_preferences
# - job_postings
# - companies
# - applications
# - application_queue
# - resumes
# - sessions
# - (and 20+ more tables)
```

#### Step 2.3: Seed Initial Data (Optional)

```bash
# Seed with sample jobs for testing
npm run db:seed

# Or seed specific data
npm run seed:jobs
```

**âš ï¸ WARNING**: Do NOT seed in production if you have real user data!

---

### Phase 3: API Deployment to Vercel (45 minutes)

#### Step 3.1: Prepare Vercel Project

```bash
# 1. Install Vercel CLI
npm install -g vercel

# 2. Login to Vercel
vercel login

# 3. Navigate to API directory
cd apps/api
```

#### Step 3.2: Configure vercel.json

Create `apps/api/vercel.json`:

```json
{
  "version": 2,
  "builds": [
    {
      "src": "src/index.ts",
      "use": "@vercel/node"
    }
  ],
  "routes": [
    {
      "src": "/(.*)",
      "dest": "src/index.ts"
    }
  ],
  "env": {
    "NODE_ENV": "production"
  }
}
```

#### Step 3.3: Set Environment Variables in Vercel

```bash
# Option A: Via CLI
vercel env add DATABASE_URL production
vercel env add REDIS_URL production
vercel env add JWT_SECRET production
vercel env add AWS_ACCESS_KEY_ID production
vercel env add AWS_SECRET_ACCESS_KEY production
vercel env add ANTHROPIC_API_KEY production

# Option B: Via Vercel Dashboard (Recommended)
# 1. Go to project settings
# 2. Navigate to Environment Variables
# 3. Add all variables from your .env file
# 4. Scope: Production
```

#### Step 3.4: Deploy API

```bash
# Deploy to production
vercel --prod

# Expected output:
# âœ… Deployment ready: https://jobswipe-api-xxx.vercel.app
# ğŸ¯ Copy this URL - you'll need it
```

#### Step 3.5: Test API Deployment

```bash
# Test health endpoint
curl https://your-api-url.vercel.app/health

# Expected response:
# {"status":"ok","timestamp":"2025-11-10T..."}

# Test detailed health
curl https://your-api-url.vercel.app/health/detailed

# Should show database and Redis connections
```

---

### Phase 4: Web App Deployment to Vercel (30 minutes)

#### Step 4.1: Configure Web App Environment

```bash
cd apps/web
```

Create `apps/web/.env.production`:

```bash
NEXT_PUBLIC_API_URL="https://your-api-url.vercel.app"
NEXT_PUBLIC_APP_URL="https://your-domain.com"
JWT_SECRET="<same-as-api>"
DATABASE_URL="<same-as-api>"
```

#### Step 4.2: Build Test

```bash
# Test production build locally
npm run build

# This should complete without errors
# If errors occur, fix them before deploying
```

#### Step 4.3: Deploy Web App

```bash
# Deploy to Vercel
vercel --prod

# Link to existing project or create new one
# Choose: apps/web

# Expected output:
# âœ… Deployment ready: https://jobswipe-xxx.vercel.app
```

#### Step 4.4: Configure Custom Domain (Optional)

```bash
# Via Vercel Dashboard:
# 1. Go to project settings
# 2. Domains
# 3. Add: yourdomain.com
# 4. Add: www.yourdomain.com
# 5. Configure DNS (follow Vercel instructions)
```

---

### Phase 5: Desktop App Distribution (60 minutes)

**âš ï¸ Important**: Desktop app is NOT deployed to cloud - users download and install it

#### Step 5.1: Build Desktop App

```bash
cd apps/desktop

# Build for all platforms
npm run package:all

# Or build for specific platforms:
npm run package:mac       # macOS
npm run package:win       # Windows
npm run package:linux     # Linux
```

#### Step 5.2: Sign Applications (CRITICAL for macOS)

**macOS Code Signing**:
```bash
# Requires Apple Developer account ($99/year)
# 1. Get Developer ID Application certificate
# 2. Configure in package.json:
{
  "build": {
    "mac": {
      "identity": "Developer ID Application: Your Name (TEAM_ID)"
    }
  }
}

# 3. Rebuild with signing
npm run package:mac
```

**Windows Code Signing**:
```bash
# Requires code signing certificate ($200-400/year)
# Options: DigiCert, Sectigo, SSL.com
```

#### Step 5.3: Distribute Desktop App

**Option A: GitHub Releases (Free)**
```bash
# 1. Create release on GitHub
# 2. Upload built packages
# 3. Users download manually
```

**Option B: Auto-Updates (Recommended)**
```bash
# Already configured with electron-updater
# 1. Upload builds to S3 or GitHub releases
# 2. Update latest.yml files
# 3. App auto-updates on launch
```

---

### Phase 6: Post-Deployment Verification (30 minutes)

#### Critical Tests Checklist

```bash
# Test 1: API Health
curl https://your-api-url.vercel.app/health
# âœ… Should return {"status":"ok"}

# Test 2: Database Connection
curl https://your-api-url.vercel.app/health/detailed
# âœ… Should show database: "connected"

# Test 3: User Registration
curl -X POST https://your-api-url.vercel.app/api/v1/auth/register \
  -H "Content-Type: application/json" \
  -d '{"email":"test@example.com","password":"Test123456!","name":"Test User"}'
# âœ… Should return user object with token

# Test 4: User Login
curl -X POST https://your-api-url.vercel.app/api/v1/auth/login \
  -H "Content-Type: application/json" \
  -d '{"email":"test@example.com","password":"Test123456!"}'
# âœ… Should return access token

# Test 5: Protected Route
curl https://your-api-url.vercel.app/api/v1/jobs \
  -H "Authorization: Bearer <token-from-login>"
# âœ… Should return jobs array

# Test 6: Web App
# Open https://your-domain.com
# âœ… Should load homepage
# âœ… Can register new user
# âœ… Can login
# âœ… Can see jobs
# âœ… Can swipe on jobs
```

---

## ğŸ›¡ï¸ SECURITY HARDENING

### Post-Deployment Security Tasks

#### 1. Enable HTTPS Everywhere
```bash
# Vercel handles this automatically
# Verify: All URLs use https://
```

#### 2. Configure CORS Properly
```bash
# In your .env:
API_CORS_ORIGIN="https://yourdomain.com,https://www.yourdomain.com"

# Test CORS:
curl -H "Origin: https://yourdomain.com" \
  -H "Access-Control-Request-Method: POST" \
  -X OPTIONS https://your-api-url.vercel.app/api/v1/auth/login
# Should return Access-Control-Allow-Origin header
```

#### 3. Rotate Default Secrets
```bash
# Generate new secrets
openssl rand -base64 48  # JWT_SECRET
openssl rand -base64 48  # JWT_REFRESH_SECRET
openssl rand -base64 32  # SESSION_SECRET

# Update in Vercel:
vercel env rm JWT_SECRET production
vercel env add JWT_SECRET production
# (paste new value)
```

#### 4. Enable Rate Limiting
```bash
# Already configured in API
# Verify it's active:
for i in {1..150}; do
  curl https://your-api-url.vercel.app/health
done
# Should start returning 429 Too Many Requests after ~100 requests
```

#### 5. Set Up Security Monitoring
```bash
# Enable Vercel Security settings:
# 1. Go to project settings
# 2. Security
# 3. Enable: DDoS Protection
# 4. Enable: Attack Mode Protection
```

---

## ğŸ“Š MONITORING & OBSERVABILITY

### Essential Monitoring Setup

#### 1. Vercel Analytics (Built-in)
```bash
# Already enabled by default
# View in Vercel dashboard:
# - Request counts
# - Response times
# - Error rates
# - Geographic distribution
```

#### 2. Database Monitoring
```bash
# Neon Dashboard:
# - Connection pool usage
# - Query performance
# - Storage usage
# - Active connections

# Set alerts for:
# - Connection pool > 80% capacity
# - Storage > 80% capacity
# - Query latency > 1000ms
```

#### 3. Application Logging
```bash
# View logs in real-time:
vercel logs --follow

# Filter by severity:
vercel logs --filter "error"

# Search logs:
vercel logs --search "database"
```

#### 4. Error Tracking with Sentry (Optional but Recommended)

```bash
# 1. Create Sentry account (free tier)
# 2. Create new project
# 3. Get DSN
# 4. Add to environment variables:
vercel env add SENTRY_DSN production

# 5. Errors will appear in Sentry dashboard
```

#### 5. Uptime Monitoring

**Use UptimeRobot (Free)**:
```bash
# 1. Go to https://uptimerobot.com
# 2. Create monitor:
#    - Type: HTTPS
#    - URL: https://your-api-url.vercel.app/health
#    - Interval: 5 minutes
# 3. Set up email alerts
```

---

## ğŸš¨ ROLLBACK PROCEDURES

### If Deployment Fails

#### Scenario 1: Database Migration Failed

```bash
# Step 1: Identify failed migration
npx prisma migrate status

# Step 2: Rollback last migration
# NOTE: Prisma doesn't support automatic rollback
# Manual process:

# 2a. Connect to database
psql $DATABASE_URL

# 2b. Manually drop tables/revert changes
# (Keep migration SQL handy for reference)

# Step 3: Re-run migration after fixing
npx prisma migrate deploy
```

**Prevention**: Always test migrations in staging first!

#### Scenario 2: API Deployment Broken

```bash
# Vercel keeps previous deployments
# Rollback instantly:

# 1. Go to Vercel dashboard
# 2. Deployments tab
# 3. Find last working deployment
# 4. Click "Promote to Production"

# Takes effect in < 1 minute
```

#### Scenario 3: Environment Variable Misconfiguration

```bash
# Fix without redeploying:

# 1. Update environment variable in Vercel
vercel env rm BROKEN_VAR production
vercel env add CORRECT_VAR production

# 2. Trigger redeploy
vercel --prod

# Or redeploy in dashboard
```

#### Scenario 4: Database Connection Issues

```bash
# Quick diagnostics:

# Test 1: Can you connect locally?
psql $DATABASE_URL
# If NO: Check connection string format

# Test 2: Is SSL required?
# Add ?sslmode=require to DATABASE_URL

# Test 3: Check IP whitelist (if applicable)
# Neon: Add 0.0.0.0/0 to allowed IPs (or Vercel IP ranges)

# Test 4: Connection pool exhausted?
# Neon dashboard: Check active connections
# Solution: Increase max connections or use connection pooling
```

#### Scenario 5: Complete System Failure

**Emergency Rollback Plan**:

```bash
# 1. Put up maintenance page
# Create apps/web/pages/maintenance.html:
<!DOCTYPE html>
<html>
<head>
  <title>JobSwipe - Maintenance</title>
</head>
<body>
  <h1>We'll be back soon!</h1>
  <p>JobSwipe is currently undergoing scheduled maintenance.</p>
  <p>We expect to be back in 30 minutes.</p>
</body>
</html>

# 2. Disable API routing temporarily
# In Vercel dashboard: Pause deployments

# 3. Communicate with users
# - Update status page
# - Send email notification
# - Update social media

# 4. Debug in staging
# - Replicate issue
# - Test fix
# - Deploy to staging
# - Verify fix works

# 5. Re-enable production
# - Deploy fix
# - Test thoroughly
# - Monitor for 30 minutes
# - Remove maintenance page
```

---

## ğŸ’° COST BREAKDOWN

### Monthly Operating Costs (Estimated)

#### Starter Setup (~$200/month)
```
Vercel Pro:                 $20/month
Neon PostgreSQL (Pro):      $69/month
Upstash Redis (Pay as go):  $10/month
AWS S3:                     $5/month
Anthropic API:              $50/month (usage-based)
Domain + SSL:               $1/month
Uptime Monitoring:          Free (UptimeRobot)
Sentry (Free tier):         $0
-------------------------------------------
TOTAL:                      ~$155/month
```

#### Growth Setup (~$500/month)
```
Vercel Pro:                 $20/month
Neon PostgreSQL (Scale):    $199/month
Upstash Redis (Pro):        $60/month
AWS S3:                     $20/month
Anthropic API:              $150/month
OpenAI API:                 $50/month
Sentry (Team):              $26/month
Email Service (SendGrid):   $20/month
-------------------------------------------
TOTAL:                      ~$545/month
```

#### Enterprise Setup (~$2000/month)
```
AWS/GCP Infrastructure:     $800/month
RDS PostgreSQL:             $400/month
ElastiCache Redis:          $200/month
S3 + CloudFront:            $100/month
Anthropic API:              $300/month
OpenAI API:                 $100/month
Monitoring Suite:           $100/month
-------------------------------------------
TOTAL:                      ~$2000/month
```

---

## ğŸ¯ POST-LAUNCH CHECKLIST

### Week 1: Monitoring & Stability

- [ ] **Day 1**: Monitor error rates every hour
- [ ] **Day 1**: Check database performance metrics
- [ ] **Day 1**: Verify all API endpoints responding
- [ ] **Day 2**: Review user registration flow
- [ ] **Day 3**: Monitor automation success rates
- [ ] **Day 5**: Review and optimize slow queries
- [ ] **Day 7**: First user feedback review

### Week 2-4: Optimization

- [ ] Enable database query logging
- [ ] Set up automated performance reports
- [ ] Optimize slow API endpoints
- [ ] Review and tune Redis cache settings
- [ ] Implement CDN for static assets
- [ ] Set up automated database backups testing
- [ ] Configure log retention policies

### Month 2: Scaling Preparation

- [ ] Review infrastructure costs
- [ ] Plan for horizontal scaling
- [ ] Set up staging environment
- [ ] Implement A/B testing framework
- [ ] Configure auto-scaling rules
- [ ] Disaster recovery drill
- [ ] Security audit

---

## âš¡ PERFORMANCE OPTIMIZATION

### Quick Wins (Do These Immediately)

#### 1. Enable Redis Caching
```typescript
// Already configured in API
// Verify it's working:
curl https://your-api-url.vercel.app/api/v1/jobs
# First request: ~500ms
# Second request: ~50ms (cached)
```

#### 2. Database Connection Pooling
```bash
# Add to DATABASE_URL:
DATABASE_URL="postgresql://...?connection_limit=20&pool_timeout=10"
```

#### 3. Enable Compression
```bash
# Vercel enables this automatically
# Verify:
curl -H "Accept-Encoding: gzip" https://your-domain.com -I
# Should see: Content-Encoding: gzip
```

#### 4. Optimize Images
```bash
# Next.js Image Optimization (automatic)
# Verify in browser DevTools:
# - Images should be WebP format
# - Proper sizing
# - Lazy loading
```

#### 5. Database Indexing
```bash
# Critical indexes already in schema.prisma:
# - user email (unique)
# - job title, company, location
# - application status, userId
# - Verify they exist:
psql $DATABASE_URL -c "\d+ users"
# Should show indexes
```

---

## ğŸ”¥ TROUBLESHOOTING GUIDE

### Common Issues & Solutions

#### Issue: "Database connection failed"

**Symptoms**: API returns 500 error, logs show database connection error

**Solutions**:
```bash
# 1. Verify DATABASE_URL format
echo $DATABASE_URL
# Should be: postgresql://user:pass@host:port/db?sslmode=require

# 2. Test connection locally
psql $DATABASE_URL

# 3. Check SSL mode
# Neon requires SSL - ensure ?sslmode=require

# 4. Check IP whitelist
# Neon dashboard > Settings > IP Allow
# Add 0.0.0.0/0 or specific Vercel IPs

# 5. Check connection pool
# Neon dashboard > Metrics > Connections
# If at limit, increase or optimize queries
```

#### Issue: "Redis connection timeout"

**Symptoms**: Sessions not persisting, queue not processing

**Solutions**:
```bash
# 1. Verify REDIS_URL
echo $REDIS_URL
# Should be: redis://default:pass@host:port

# 2. Test connection
redis-cli -u $REDIS_URL ping
# Should return: PONG

# 3. Check TLS requirement
# Upstash requires TLS
# Ensure rediss:// (with double 's') if TLS required

# 4. Check connection limits
# Upstash dashboard > Metrics
```

#### Issue: "S3 upload failed"

**Symptoms**: Resume upload returns error

**Solutions**:
```bash
# 1. Verify AWS credentials
aws s3 ls s3://your-bucket-name
# Should list bucket contents

# 2. Check IAM permissions
# User should have: s3:PutObject, s3:GetObject

# 3. Verify bucket exists
aws s3api head-bucket --bucket your-bucket-name

# 4. Check CORS configuration
# In S3 bucket settings > CORS:
[
  {
    "AllowedHeaders": ["*"],
    "AllowedMethods": ["GET", "PUT", "POST", "DELETE"],
    "AllowedOrigins": ["https://yourdomain.com"],
    "ExposeHeaders": ["ETag"]
  }
]
```

#### Issue: "API returns 429 Too Many Requests"

**Symptoms**: Legitimate users getting rate limited

**Solutions**:
```bash
# 1. Check current limits
# In .env:
RATE_LIMIT_MAX_REQUESTS=100
RATE_LIMIT_WINDOW=900000  # 15 minutes

# 2. Increase limits for production
RATE_LIMIT_MAX_REQUESTS=500
RATE_LIMIT_WINDOW=900000

# 3. Implement user-based rate limiting
# (Already configured in API - uses JWT to identify users)

# 4. Whitelist specific IPs (if needed)
# Add to API configuration
```

#### Issue: "Desktop app won't connect to API"

**Symptoms**: Desktop app shows "Connection error"

**Solutions**:
```bash
# 1. Verify API URL in desktop app
# apps/desktop/src/config.ts:
const API_URL = "https://your-api-url.vercel.app"

# 2. Check CORS settings
# API should allow desktop app origin

# 3. Rebuild desktop app with correct URL
cd apps/desktop
npm run build
npm run package

# 4. Test API from desktop app network
curl https://your-api-url.vercel.app/health
```

---

## ğŸ“ EMERGENCY CONTACTS & RESOURCES

### Critical Service Support

| Service | Support | Response Time | Contact |
|---------|---------|---------------|---------|
| **Vercel** | Email + Chat | < 1 hour | support@vercel.com |
| **Neon** | Email + Discord | < 4 hours | support@neon.tech |
| **Upstash** | Email | < 24 hours | support@upstash.com |
| **AWS** | Premium Support | < 1 hour | AWS Console |
| **Anthropic** | Email | < 24 hours | support@anthropic.com |

### Monitoring Dashboards

```bash
# Save these URLs:
Vercel Dashboard:    https://vercel.com/dashboard
Neon Dashboard:      https://console.neon.tech
Upstash Dashboard:   https://console.upstash.com
AWS Console:         https://console.aws.amazon.com
Sentry:              https://sentry.io
UptimeRobot:         https://uptimerobot.com
```

---

## âœ… FINAL PRE-LAUNCH CHECKLIST

### Business Readiness
- [ ] Domain purchased and DNS configured
- [ ] SSL certificates valid (Vercel handles this)
- [ ] Privacy policy published
- [ ] Terms of service published
- [ ] GDPR compliance verified
- [ ] Data retention policies configured
- [ ] User data export functionality tested
- [ ] Account deletion functionality tested

### Technical Readiness
- [ ] All environment variables set and verified
- [ ] Database migrations completed successfully
- [ ] Redis connection confirmed
- [ ] S3 bucket configured and tested
- [ ] API health checks passing
- [ ] Web app loads and functions correctly
- [ ] Desktop app distributed and tested
- [ ] Automated backups configured
- [ ] Monitoring and alerts configured
- [ ] Error tracking configured (Sentry)
- [ ] Rate limiting tested
- [ ] Authentication flow tested (register/login/logout)
- [ ] Job browsing tested
- [ ] Job application automation tested
- [ ] Resume upload tested

### Security Readiness
- [ ] All secrets rotated from defaults
- [ ] HTTPS enforced everywhere
- [ ] CORS configured correctly
- [ ] Rate limiting active
- [ ] Input validation tested
- [ ] SQL injection protection verified
- [ ] XSS protection verified
- [ ] CSRF protection enabled
- [ ] Password hashing verified (bcrypt)
- [ ] JWT expiration configured
- [ ] Security headers configured

### Operational Readiness
- [ ] Rollback procedure documented
- [ ] Monitoring dashboards bookmarked
- [ ] Support contact list created
- [ ] Incident response plan ready
- [ ] Team trained on deployment process
- [ ] Communication plan for downtime
- [ ] Status page set up (optional)

---

## ğŸ“ LESSONS FROM THE TRENCHES

### What Could Go Wrong (And How to Prevent It)

#### 1. Database Migration Failure
**Prevention**:
- Always test migrations in staging first
- Back up database before migrating
- Use Prisma's `migrate deploy` (not `migrate dev` in production)

#### 2. Environment Variable Mismatch
**Prevention**:
- Use `.env.example` as template
- Validate all required variables before deploy
- Never commit real secrets to git

#### 3. Connection Pool Exhaustion
**Prevention**:
- Set connection limits in DATABASE_URL
- Use Prisma connection pooling
- Monitor connection usage

#### 4. API Rate Limiting Users
**Prevention**:
- Set reasonable rate limits
- Implement user-based limits (not just IP)
- Provide clear error messages

#### 5. S3 Upload Permissions
**Prevention**:
- Test IAM permissions before going live
- Use least-privilege principle
- Enable CloudTrail for audit logging

---

## ğŸš€ LAUNCH DAY PROTOCOL

### T-24 Hours: Final Preparations
```bash
âœ… All checklist items completed
âœ… Team briefed on launch plan
âœ… Monitoring dashboards open
âœ… Support channels ready
âœ… Announcement prepared
```

### T-1 Hour: Pre-Flight Check
```bash
# 1. Test all critical paths
curl https://your-api-url.vercel.app/health
# Open https://yourdomain.com
# Register test user
# Login
# Browse jobs
# Swipe on job
# Check automation queue

# 2. Verify monitoring
# All dashboards showing green

# 3. Clear any test data
# psql $DATABASE_URL
# DELETE FROM users WHERE email LIKE '%test%';
```

### T-0: LAUNCH
```bash
# 1. Remove maintenance mode (if any)
# 2. Send announcement
# 3. Monitor for first 2 hours
#    - Watch error logs
#    - Check response times
#    - Monitor user registrations
#    - Verify automation working
```

### T+1 Hour: First Check-in
```bash
# Review metrics:
# - New user registrations
# - Error rate (should be < 1%)
# - API response time (should be < 500ms p95)
# - Database connections (should be < 50% capacity)
```

### T+24 Hours: First Review
```bash
# Comprehensive review:
# - Total users registered
# - Total jobs browsed
# - Total applications submitted
# - Error patterns
# - Performance bottlenecks
# - User feedback
# - Cost tracking
```

---

## ğŸ“ˆ SUCCESS METRICS

### Define "Success" Before Launch

```bash
Week 1 Goals:
- 99.9% uptime
- < 1% error rate
- 100+ user registrations
- 500+ job views
- 50+ job applications
- < 500ms API response time (p95)

Month 1 Goals:
- 99.95% uptime
- < 0.5% error rate
- 1,000+ active users
- 10,000+ job views
- 1,000+ applications
- 70%+ automation success rate
```

---

## ğŸ‰ CONGRATULATIONS!

If you've made it this far, you have:

âœ… **Infrastructure set up** and secured
âœ… **Application deployed** to production
âœ… **Monitoring configured** for peace of mind
âœ… **Rollback plan** ready for emergencies
âœ… **Team prepared** for launch day

### What's Next?

1. **Week 1**: Monitor intensively, fix issues quickly
2. **Week 2-4**: Optimize performance, gather user feedback
3. **Month 2**: Plan scaling, add features
4. **Month 3+**: Achieve product-market fit, scale aggressively

---

## ğŸ“ NEED HELP?

This deployment guide was created after comprehensive repository analysis. If you encounter issues:

1. **Check this guide first** - 90% of issues are covered
2. **Review application logs** - Most errors are self-explanatory
3. **Test in staging** - Never debug in production
4. **Ask specific questions** - "It doesn't work" is not helpful

### Additional Resources

- **Repository**: All code is well-documented
- **CLAUDE.md**: Development guidelines and architecture
- **README.md**: Quick start guide
- **TESTING_GUIDE.md**: Comprehensive testing procedures

---

**Remember**: Deployment is not the finish line, it's the starting line.

**Good luck with your launch! ğŸš€**

---

*Last Updated: 2025-11-10*
*Version: 1.0*
*Prepared by: DevOps CTO*
